{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import stanza\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load(\"en_core_web_md\")\n",
    "spacy_es = spacy.load(\"es_core_news_md\")\n",
    "stanza_en = stanza.Pipeline(\"en\", processors=\"tokenize,ner\", package={\"ner\": [\"conll03\"]})\n",
    "stanza_es = stanza.Pipeline(\"es\", processors=\"tokenize,ner\", package={\"ner\": [\"conll02\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_europarl(filepath):\n",
    "    \"\"\"Load the data from a europarl conll02-file\n",
    "\n",
    "    args: filepath (string, full path of the europarl file)\n",
    "\n",
    "    return: words (list of all words in the file), labels (list of all labels), text (string of continuous text)\n",
    "\n",
    "    note: the file path depends on the storage location of the file on the computer, and can vary from computer to computer\n",
    "    \"\"\"\n",
    "    \n",
    "    words = []\n",
    "    labels = []\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            parts = line.split(\"\\t\")\n",
    "\n",
    "            if len(parts) > 1:\n",
    "                label = parts[1]\n",
    "                label = label[:-1]\n",
    "\n",
    "                words.append(parts[0])\n",
    "                labels.append(label)\n",
    "\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return words, labels, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subtitles(filepath):\n",
    "    \"\"\"Load movie subtitle txt-file, and remove blank lines and line breaks\n",
    "\n",
    "    args: filepath (string, full path of the subtitle file)\n",
    "\n",
    "    return: text (string of continuous text without blank lines and line breaks)\n",
    "\n",
    "    note: the file path depends on the storage location of the file on the computer, and can vary from computer to computer\n",
    "    \"\"\"\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            if line.strip():\n",
    "                text += line.strip(\"\\n\") + \" \"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text, model, lang):\n",
    "    \"\"\"Process the given text, and return the list of recognized Named Entities\n",
    "\n",
    "    args: text (string, continuous text), model (string, language model to be used i.e. spaCy or Stanza), language (string, language of the text)\n",
    "\n",
    "    return: tuple (list of all recognized Named Entities and non recognized Named Entities in the BIOES and the time to process the NER with the given NLP tool).\n",
    "\n",
    "    note: when specifying the language, please use \"en\" for English and \"es\" for Spanish, and please write the names of the language models in lower case letters only\n",
    "    \"\"\"\n",
    "\n",
    "    if model == \"spacy\":\n",
    "        if lang == \"en\":\n",
    "            doc = spacy_en(text)\n",
    "        elif lang == \"es\":\n",
    "            doc = spacy_es(text)\n",
    "    elif model == \"stanza\":\n",
    "        if lang == \"en\":\n",
    "            #   Note regarding TIMER: The time will be different on each ussage (making each time output an estimation of the general performance time), \n",
    "            #       since the time is affected by the PC's performance and background application might \"spike\" the time/performance of the function.\n",
    "            #       Instead we could use the modul \"timeit\", although we would need to perform stanza_en(text) twice or more,\n",
    "            #       because timeit runs the method multiple times (without returning anything besides time),\n",
    "            #       therefore it increasies the overall performance of the program.   \n",
    "            start = perf_counter()\n",
    "            doc = stanza_en(text)\n",
    "            end = perf_counter()\n",
    "            execution_time = (end - start)\n",
    "            return [f'{token.text}\\t{token.ner}\\n' for sent in doc.sentences for token in sent.tokens], execution_time\n",
    "        elif lang == \"es\":\n",
    "            start = perf_counter()\n",
    "            doc = stanza_es(text)\n",
    "            end = perf_counter()\n",
    "            execution_time = (end - start)\n",
    "            return [f'{token.text}\\t{token.ner}\\n' for sent in doc.sentences for token in sent.tokens], execution_time\n",
    "    return doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_en = \"D:/OperaDownloads/Multilingual_NER-main/Multilingual_NER-main/Europarl Corpus/en-europarl.test.conll02\"\n",
    "w_en, l_en, t_en = load_europarl(path_en)\n",
    "path_es = \"D:/OperaDownloads/Multilingual_NER-main/Multilingual_NER-main/Europarl Corpus/es-europarl.test.conll02\"\n",
    "w_es, l_es, t_es = load_europarl(path_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_sp = ner(t_es, \"spacy\", \"es\")\n",
    "print(\"spaCy: \" + str(len(entities_sp)))\n",
    "#for ent in entities_sp:\n",
    "#    print(f\"{ent.text:<25}{ent.label_:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_st, time = ner(t_es, \"stanza\", \"es\")\n",
    "print(*entities_st, sep = '\\n')\n",
    "#print(time)\n",
    "#print(\"Stanza: \" + str(len(entities_st)))\n",
    "#for ent in entities_st:\n",
    "#    print(f\"{ent.text:<25}{ent.type:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entities_sp = ner(text, \"spacy\", \"en\")\n",
    "#for ent in entities_sp:\n",
    "#    print(f\"{ent.text:<25}{ent.label_:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_europarl_testpurp(filepath):\n",
    "    \"\"\"Load the data from a europarl conll02-file without splitting the file into: words, labels, text \n",
    "\n",
    "    args: filepath (string, full path of the europarl file)\n",
    "\n",
    "    return: the file (as a string)\n",
    "\n",
    "    note: Only here for test purposes to see about comparing the NER outputs, since turning spacy into the BIOES format as yet to be done (will take somem more time (I assume)). \n",
    "    \"\"\"\n",
    "    text = []\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            parts = line.split(\"\\t\")\n",
    "            text.append(line)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_en = \"D:/OperaDownloads/Multilingual_NER-main/Multilingual_NER-main/Europarl Corpus/en-europarl.test.conll02\"\n",
    "test_text = load_europarl_testpurp(test_path_en)\n",
    "print(*test_text, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           These texts are there to help to check if differences can be properly checked.\n",
    "\n",
    "#text2 = \"Chris Manning teaches at Stanford University. He lives in the Tauern Tunnel.\"\n",
    "text3 = \"All the same, we must content ourselves with enacting European law to ensure greater safety\"\n",
    "\n",
    "entities_st, time = ner(text3, \"stanza\", \"en\")\n",
    "print(time)\n",
    "print(type(entities_st))\n",
    "print(*entities_st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = list(set(entities_st) - set(test_text))\n",
    "print(*difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for difference works, although it just shows which words are not included but not what is different about it.\n",
    "\n",
    "Just down below here, we can see the text extract from the europarl file. \"law\" is labled here (with \"European\") as a Misc, to be exact as a I-MISC.\n",
    "All\tO\n",
    " the\tO\n",
    " same\tO\n",
    " ,\tO\n",
    " we\tO\n",
    " must\tO\n",
    " content\tO\n",
    " ourselves\tO\n",
    " with\tO\n",
    " enacting\tO\n",
    " European\tB-MISC\n",
    " law\tI-MISC     *HERE\n",
    " to\tO\n",
    " ensure\tO\n",
    " greater\tO\n",
    " safety\tO\n",
    "\n",
    "With our NER outcome \"law\" isn't labled as a (I-)MISC but rather as a O.\n",
    "\n",
    "Now, while checking for differences, the method has correctly determined that there is no instance of \"European\" being labled with S-MISC in the file. \n",
    "However, it doesn't mark \"law\" labled with O as a difference, the reason for that is that in the file there are instances of \"law\" being labled as such.\n",
    "This will make duplicate differences appearing in different spots slip under the radar of the method.\n",
    "\n",
    "\n",
    "Suggestion solution: \n",
    "We compare each line/word from both NER outcomes one at a time and compare them for differences. Placing the differences into a list each time a difference is found.\n",
    "The sequence will stay correct and multiple instances the same difference in different spots will be recognized.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: wes\tO\n",
      "stanza: we\tO\n",
      "\n",
      " test: European\tB-MISC\n",
      "stanza: European\tS-MISC\n",
      "\n",
      " test: law\tI-MISC\n",
      "stanza: law\tO\n",
      "\n",
      " test: law\tO\n",
      "stanza: to\tO\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_text2 = ['All\\tO\\n', 'the\\tO\\n', 'same\\tO\\n', ',\\tO\\n', 'wes\\tO\\n', 'must\\tO\\n', 'content\\tO\\n', 'ourselves\\tO\\n', 'with\\tO\\n', 'enacting\\tO\\n', 'European\\tB-MISC\\n', 'law\\tI-MISC\\n', 'law\\tO\\n', 'ensure\\tO\\n', 'greater\\tO\\n', 'safety\\tO\\n']\n",
    "#Absichtlicher Fehler in \"wes\"/\"we\".\n",
    "differences = []\n",
    "for i in range(len(test_text2)):\n",
    "    if not test_text2[i] == entities_st[i]:\n",
    "        differences.append(f\"test: {test_text2[i]}stanza: {entities_st[i]}\\n\")\n",
    "print(*differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           Checking that the Subtitles \n",
    "\n",
    "path_eh = \"D:/OperaDownloads/Multilingual_NER-main/Multilingual_NER-main/Movie subtitles/El Hoyo (ES).txt\"\n",
    "\n",
    "#print(load_subtitles(path_eh))\n",
    "path_bttf = \"D:/OperaDownloads/Multilingual_NER-main/Multilingual_NER-main/Movie subtitles/El Hoyo (EN).txt\"\n",
    "\n",
    "#text = load_subtitles(path_bttf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
